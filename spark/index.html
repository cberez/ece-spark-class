<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>ADALTAS - Spark</title>

    <meta name="description" content="In memory processing engine">
    <meta name="author" content="César Berezowski">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="reveal.js/css/reveal.css">
    <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css': 'reveal.js/css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

  <div style="position:absolute; top:20px; left:20px;">
  <p><img src="img/adaltas.png" width="200px" style="margin: 10px 0" /></p>
  </div>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        
<section>
<h1>Spark</h1>
<h2>In memory processing</h2>
<img src="./spark.png" style="border:none;background:transparent" />
</section>

<section data-markdown>
<script type="text/template">
## What is it ?
</script>
</section>

<section data-markdown>
<script type="text/template">
## Historically

* RAM was very expensive
* Network was slow 
* MapReduce allows for computation of huge datasets (cheap hard drives)
* Limited to Java 
* Only batch processing 
</script>
</section>

<section data-markdown>
<script type="text/template">
### But today ?

* RAM is cheap: 256GB+ of RAM servers !
* Virtual machines everywhere 
* Speedy network
* Multi-core machines
</script>
</section>

<section data-markdown>
<script type="text/template">
### What is Spark ?

* In-memory processing engine 
* Unified platform for Big Data apps
* Runs on Hadoop (and other platforms)
* Access data from multiple sources (HDFS, HBase, Hive, Cassandra…)
* 100x faster than MR !
</script>
</section>

<section data-markdown>
<script type="text/template">
### In more details

* Developed at UC Berkeley 
* Written in Scala
* Open Source Apache project living on GitHub
* Current version: 2.2
* Distributed version: 1.6+ / 2.1
</script>
</section>

<section data-markdown>
<script type="text/template">
### How to use it?

* Shells: 
  - `spark-shell`
  - `pyspark` 
* Submit a jar / python file: `spark-submit`  
* Interactive GUI: Zeppelin, Jupyter, Hue, ...
</script>
</section>

<section data-markdown>
<script type="text/template">
### Core principles

* Data stored in RDD for every different processing (Resilient Distributed Dataset)
* Apply two types of operations:
  - Transformations
  - Actions
* Lazy evaluation
</script>
</section>

<section data-markdown>
<script type="text/template">
### RDD: Data Unification

* Immutable collection of objects
* Resilient: lost data can be recomputed
* Partitioned &amp; distributed on a cluster
* Fault tolerant
* Can be cached
</script>
</section>

<section data-markdown>
<script type="text/template">
### Transformation VS Action

* Transformation: 
  - Create a new RDD from an existing one 
  - Ex: filter, map, …
* Action: 
  - Apply transformations &amp; generate an output
  - Ex: count, collect, write…
</script>
</section>

<section data-markdown>
<script type="text/template">
### Lazy evaluation

* Computation happens when needed
* If a partition is lost, recompute it from the last point
* Optimized workflow (DAG)
</script>
</section>

<section data-markdown>
<script type="text/template">
### RDD Processing

![rdds.png](./rdds.png)
[Source](https://dzone.com/refcardz/apache-spark)
</script>
</section>

<section data-markdown>
<script type="text/template">
### The big 4s

Multiple libraries:
* SparkSQL -> Dataframes (Hive, Impala)
* Spark Streaming -> Micro-batching (Storm)
* MLlib -> Machine Learning (Mahout, Oryx, ...)
* GraphX ->  OLAP Graph Processing (Giraphe)
</script>
</section>

<section data-markdown>
<script type="text/template">
### Questions ? 
</script>
</section>

<section data-markdown>
<script type="text/template">
## Internals 
</script>
</section>

<section data-markdown>
<script type="text/template">
### What is a spark app  

* Java / Scala / Python code 
* Imports spark libraries (Maven / SBT / Pip)
* Start a SparkContext 
* Do some processing (read data, transform, write, ...)
* Close the SparkContext 
</script>
</section>

<section data-markdown>
<script type="text/template">
### Architecture side 

* Two components 
  - Driver: 1 (Master)
  - Executors: 1+ (Slave)
</script>
</section>

<section data-markdown>
<script type="text/template">
### Driver

* Application entry point 
* Starts the SparkContext 
* Drives the executors
* Loads unsplit data
</script>
</section>

<section data-markdown>
<script type="text/template">
### Executors

* Where the magic happens
* Executes "tasks" on partitionned RDDs
</script>
</section>

<section data-markdown>
<script type="text/template">
### Architecture side 
  
![archi.png](./archi.png)
[Source](https://dzone.com/refcardz/apache-spark)
</script>
</section>

<section data-markdown>
<script type="text/template">
### Running on Yarn 
  
* Two modes with arg `--master`
  - `yarn-client`: executors on yarn with localized driver
  - `yarn-cluster`: everything in yarn 
* Logs in yarn (except driver if client mode)
* Use `--files` to use external files (conf, ...)
</script>
</section>

<section data-markdown>
<script type="text/template">
### Examples 

* Use `spark-shell` first and then compile a Jar
* Re-use streaming advanced dataset 
* Load it in driver 
* Observe behaviour in yarn and parallelization 
* Do the same with a packaged application
</script>
</section>

<section data-markdown>
<script type="text/template">
### Questions ?
</script>
</section>

<section data-markdown>
<script type="text/template">
### Resources

* Spark's programming guides [1.6.0](https://spark.apache.org/docs/1.6.0/programming-guide.html) & [2.2.0](https://spark.apache.org/docs/latest/rdd-programming-guide.html)
* Tuning a spark job [part 1](https://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/) & [part 2](https://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/)

</script>
</section>



      </div>

    </div>

    <script src="reveal.js/lib/js/head.min.js"></script>
    <script src="reveal.js/js/reveal.js"></script>

    <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        transition: 'slide', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });

    </script>

  </body>
</html>
